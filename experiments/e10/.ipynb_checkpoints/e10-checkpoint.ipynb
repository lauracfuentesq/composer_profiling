{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da995ba8-14b1-40d6-ba26-5175e2ce5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from miditok import REMI\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae38028f-fad3-451e-a3da-bafc259fe8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import features_vectors as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35428199-2132-4c9e-b5a5-b7c40fa639e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'features_vectors' from '/mnt/nfs_share_magnet1/lafuente/symbolic_music/author-profiling/experiments/e10/features_vectors.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae5e4130-7212-4cb3-ad7f-a30ccb51fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('../../train data/type0_train_set_2.csv')\n",
    "validation_data=pd.read_csv('../../train data/type0_validation_set_2.csv')\n",
    "test_data=pd.read_csv('../../train data/type0_test_set_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f860c2-b3d5-40cb-813e-f6b0f6d4c621",
   "metadata": {},
   "source": [
    "## 1. Get features vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71328b20-ffd4-4674-9990-f07257893fc5",
   "metadata": {},
   "source": [
    "### 1.1 Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5551ec47-e625-475f-863f-f0f03e0976ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs_share_magnet1/lafuente/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/miditok/midi_tokenizer.py:3252: UserWarning: The special token PAD_None is present twice in your configuration. Skipping its duplicated occurrence.\n",
      "  self.config = TokenizerConfig()\n",
      "/mnt/nfs_share_magnet1/lafuente/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/miditok/classes.py:702: UserWarning: The special token PAD_None is present twice in your configuration. Skipping its duplicated occurrence.\n",
      "  return cls(**input_dict, **kwargs)\n",
      "/mnt/nfs_share_magnet1/lafuente/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/miditok/classes.py:702: UserWarning: Argument nb_tempos has been renamed num_tempos, you should consider to updateyour code with this new argument name.\n",
      "  return cls(**input_dict, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "val_dataloader=utils.create_data_loader(scores_df=validation_data,paths_column_name='type0_path')\n",
    "train_dataloader=utils.create_data_loader(scores_df=train_data,paths_column_name='type0_path')\n",
    "test_dataloader=utils.create_data_loader(scores_df=test_data,paths_column_name='type0_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fd8ca45-ad45-4675-bbe3-072499c0045b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([766, 1022])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6558569-e2d8-4c16-9702-854227399bd5",
   "metadata": {},
   "source": [
    "### 1.2 Get feature vectors from pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b266e69-1c68-4851-a33c-3652656db10f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "computing feature tensors: 100%|██████████████| 154/154 [07:11<00:00,  2.80s/it]\n"
     ]
    }
   ],
   "source": [
    "train_feature_vectors=utils.get_feature_vectors(dataloader=train_dataloader,\n",
    "                                                dataframe=train_data,\n",
    "                                                set_type='train', \n",
    "                                                feature_tensors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e42e90-81bb-4bb4-9fd9-00730ef59a21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenize_datasets\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "tokenize_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49287585-92fb-4509-bf43-0d44efaacb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>523255</th>\n",
       "      <th>523256</th>\n",
       "      <th>523257</th>\n",
       "      <th>523258</th>\n",
       "      <th>523259</th>\n",
       "      <th>523260</th>\n",
       "      <th>523261</th>\n",
       "      <th>523262</th>\n",
       "      <th>523263</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.596922</td>\n",
       "      <td>-0.570097</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>-0.578611</td>\n",
       "      <td>-1.018962</td>\n",
       "      <td>0.393136</td>\n",
       "      <td>1.160797</td>\n",
       "      <td>-1.027660</td>\n",
       "      <td>0.902073</td>\n",
       "      <td>-1.307048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.976666</td>\n",
       "      <td>3.019036</td>\n",
       "      <td>2.812744</td>\n",
       "      <td>-1.197109</td>\n",
       "      <td>5.509378</td>\n",
       "      <td>-3.255963</td>\n",
       "      <td>4.103693</td>\n",
       "      <td>0.323291</td>\n",
       "      <td>1.743264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.596922</td>\n",
       "      <td>-0.570097</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>-0.578611</td>\n",
       "      <td>-1.018962</td>\n",
       "      <td>0.393136</td>\n",
       "      <td>1.160797</td>\n",
       "      <td>-1.027660</td>\n",
       "      <td>0.902073</td>\n",
       "      <td>-1.307048</td>\n",
       "      <td>...</td>\n",
       "      <td>5.023933</td>\n",
       "      <td>0.370633</td>\n",
       "      <td>-2.569488</td>\n",
       "      <td>-4.027664</td>\n",
       "      <td>-1.294408</td>\n",
       "      <td>-1.124032</td>\n",
       "      <td>2.313343</td>\n",
       "      <td>4.045125</td>\n",
       "      <td>-1.559183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.596922</td>\n",
       "      <td>-0.570097</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>-0.578611</td>\n",
       "      <td>-1.018962</td>\n",
       "      <td>0.393136</td>\n",
       "      <td>1.160797</td>\n",
       "      <td>-1.027660</td>\n",
       "      <td>0.902073</td>\n",
       "      <td>-1.307048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259363</td>\n",
       "      <td>3.518903</td>\n",
       "      <td>-0.029925</td>\n",
       "      <td>-0.627152</td>\n",
       "      <td>0.309546</td>\n",
       "      <td>-2.037321</td>\n",
       "      <td>2.983413</td>\n",
       "      <td>-4.080976</td>\n",
       "      <td>3.497721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.596922</td>\n",
       "      <td>-0.570097</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>-0.578611</td>\n",
       "      <td>-1.018962</td>\n",
       "      <td>0.393136</td>\n",
       "      <td>1.160797</td>\n",
       "      <td>-1.027660</td>\n",
       "      <td>0.902073</td>\n",
       "      <td>-1.307048</td>\n",
       "      <td>...</td>\n",
       "      <td>7.752849</td>\n",
       "      <td>7.339010</td>\n",
       "      <td>-1.481044</td>\n",
       "      <td>-5.806083</td>\n",
       "      <td>1.113300</td>\n",
       "      <td>-1.434783</td>\n",
       "      <td>-0.232563</td>\n",
       "      <td>3.434355</td>\n",
       "      <td>4.890814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.596922</td>\n",
       "      <td>-0.570097</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>-0.578611</td>\n",
       "      <td>-1.018962</td>\n",
       "      <td>0.393136</td>\n",
       "      <td>1.160797</td>\n",
       "      <td>-1.027660</td>\n",
       "      <td>0.902073</td>\n",
       "      <td>-1.307048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.385188</td>\n",
       "      <td>2.989801</td>\n",
       "      <td>-0.048304</td>\n",
       "      <td>-1.567928</td>\n",
       "      <td>1.015937</td>\n",
       "      <td>-4.756809</td>\n",
       "      <td>-0.957712</td>\n",
       "      <td>-3.365838</td>\n",
       "      <td>-2.669045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0.596922</td>\n",
       "      <td>-0.570097</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>-0.578611</td>\n",
       "      <td>-1.018962</td>\n",
       "      <td>0.393136</td>\n",
       "      <td>1.160797</td>\n",
       "      <td>-1.027660</td>\n",
       "      <td>0.902073</td>\n",
       "      <td>-1.307048</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.550703</td>\n",
       "      <td>-0.999097</td>\n",
       "      <td>-2.319650</td>\n",
       "      <td>-0.001127</td>\n",
       "      <td>4.080516</td>\n",
       "      <td>-2.437918</td>\n",
       "      <td>4.498649</td>\n",
       "      <td>0.360997</td>\n",
       "      <td>4.624251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0.596922</td>\n",
       "      <td>-0.570097</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>-0.578611</td>\n",
       "      <td>-1.018962</td>\n",
       "      <td>0.393136</td>\n",
       "      <td>1.160797</td>\n",
       "      <td>-1.027660</td>\n",
       "      <td>0.902073</td>\n",
       "      <td>-1.307048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505214</td>\n",
       "      <td>4.527923</td>\n",
       "      <td>2.526645</td>\n",
       "      <td>1.624734</td>\n",
       "      <td>0.591372</td>\n",
       "      <td>-9.274305</td>\n",
       "      <td>-1.012130</td>\n",
       "      <td>-6.187698</td>\n",
       "      <td>-1.579150</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.596922</td>\n",
       "      <td>-0.570097</td>\n",
       "      <td>0.610556</td>\n",
       "      <td>-0.578611</td>\n",
       "      <td>-1.018962</td>\n",
       "      <td>0.393136</td>\n",
       "      <td>1.160797</td>\n",
       "      <td>-1.027660</td>\n",
       "      <td>0.902073</td>\n",
       "      <td>-1.307048</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.001412</td>\n",
       "      <td>1.268846</td>\n",
       "      <td>1.733484</td>\n",
       "      <td>-4.052675</td>\n",
       "      <td>1.156318</td>\n",
       "      <td>-2.986603</td>\n",
       "      <td>1.308117</td>\n",
       "      <td>-2.598691</td>\n",
       "      <td>5.225871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.560331</td>\n",
       "      <td>-0.478580</td>\n",
       "      <td>0.545430</td>\n",
       "      <td>-0.190157</td>\n",
       "      <td>-1.042293</td>\n",
       "      <td>0.257835</td>\n",
       "      <td>1.267851</td>\n",
       "      <td>-0.792130</td>\n",
       "      <td>0.806118</td>\n",
       "      <td>-1.270586</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.194752</td>\n",
       "      <td>2.965823</td>\n",
       "      <td>-0.004855</td>\n",
       "      <td>-0.765455</td>\n",
       "      <td>2.042176</td>\n",
       "      <td>-2.495970</td>\n",
       "      <td>4.809264</td>\n",
       "      <td>-3.626731</td>\n",
       "      <td>-1.467992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.668436</td>\n",
       "      <td>-0.618580</td>\n",
       "      <td>0.654014</td>\n",
       "      <td>-0.505268</td>\n",
       "      <td>-0.998379</td>\n",
       "      <td>0.207020</td>\n",
       "      <td>1.110111</td>\n",
       "      <td>-1.110785</td>\n",
       "      <td>1.181856</td>\n",
       "      <td>-1.451202</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.491082</td>\n",
       "      <td>1.552446</td>\n",
       "      <td>-2.671888</td>\n",
       "      <td>-4.223690</td>\n",
       "      <td>2.592583</td>\n",
       "      <td>-2.260444</td>\n",
       "      <td>2.415664</td>\n",
       "      <td>0.638671</td>\n",
       "      <td>2.792053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>766 rows × 523265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.596922 -0.570097  0.610556 -0.578611 -1.018962  0.393136  1.160797   \n",
       "1    0.596922 -0.570097  0.610556 -0.578611 -1.018962  0.393136  1.160797   \n",
       "2    0.596922 -0.570097  0.610556 -0.578611 -1.018962  0.393136  1.160797   \n",
       "3    0.596922 -0.570097  0.610556 -0.578611 -1.018962  0.393136  1.160797   \n",
       "4    0.596922 -0.570097  0.610556 -0.578611 -1.018962  0.393136  1.160797   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "761  0.596922 -0.570097  0.610556 -0.578611 -1.018962  0.393136  1.160797   \n",
       "762  0.596922 -0.570097  0.610556 -0.578611 -1.018962  0.393136  1.160797   \n",
       "763  0.596922 -0.570097  0.610556 -0.578611 -1.018962  0.393136  1.160797   \n",
       "764  0.560331 -0.478580  0.545430 -0.190157 -1.042293  0.257835  1.267851   \n",
       "765  0.668436 -0.618580  0.654014 -0.505268 -0.998379  0.207020  1.110111   \n",
       "\n",
       "            7         8         9  ...    523255    523256    523257  \\\n",
       "0   -1.027660  0.902073 -1.307048  ... -0.976666  3.019036  2.812744   \n",
       "1   -1.027660  0.902073 -1.307048  ...  5.023933  0.370633 -2.569488   \n",
       "2   -1.027660  0.902073 -1.307048  ...  0.259363  3.518903 -0.029925   \n",
       "3   -1.027660  0.902073 -1.307048  ...  7.752849  7.339010 -1.481044   \n",
       "4   -1.027660  0.902073 -1.307048  ... -0.385188  2.989801 -0.048304   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "761 -1.027660  0.902073 -1.307048  ... -4.550703 -0.999097 -2.319650   \n",
       "762 -1.027660  0.902073 -1.307048  ... -0.505214  4.527923  2.526645   \n",
       "763 -1.027660  0.902073 -1.307048  ... -1.001412  1.268846  1.733484   \n",
       "764 -0.792130  0.806118 -1.270586  ... -3.194752  2.965823 -0.004855   \n",
       "765 -1.110785  1.181856 -1.451202  ... -4.491082  1.552446 -2.671888   \n",
       "\n",
       "       523258    523259    523260    523261    523262    523263  label  \n",
       "0   -1.197109  5.509378 -3.255963  4.103693  0.323291  1.743264      0  \n",
       "1   -4.027664 -1.294408 -1.124032  2.313343  4.045125 -1.559183      1  \n",
       "2   -0.627152  0.309546 -2.037321  2.983413 -4.080976  3.497721      0  \n",
       "3   -5.806083  1.113300 -1.434783 -0.232563  3.434355  4.890814      1  \n",
       "4   -1.567928  1.015937 -4.756809 -0.957712 -3.365838 -2.669045      0  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "761 -0.001127  4.080516 -2.437918  4.498649  0.360997  4.624251      1  \n",
       "762  1.624734  0.591372 -9.274305 -1.012130 -6.187698 -1.579150      1  \n",
       "763 -4.052675  1.156318 -2.986603  1.308117 -2.598691  5.225871      1  \n",
       "764 -0.765455  2.042176 -2.495970  4.809264 -3.626731 -1.467992      1  \n",
       "765 -4.223690  2.592583 -2.260444  2.415664  0.638671  2.792053      0  \n",
       "\n",
       "[766 rows x 523265 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c6414a-63a6-46de-b21c-f989177caea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors: 100%|████████████████| 22/22 [00:59<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "val_feature_vectors=utils.get_feature_vectors(dataloader=val_dataloader,\n",
    "                                                dataframe=validation_data,\n",
    "                                                set_type='val', \n",
    "                                                feature_tensors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3183b6-2b68-4ecf-a5da-206059acb9f1",
   "metadata": {},
   "source": [
    "## 2. Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6b17966-7fcc-4286-90e8-3c89edc28f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "seed = 42\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "class DatasetMLP(Dataset):\n",
    "\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self,ind):\n",
    "        x=self.data[ind][:-1]\n",
    "        y=self.data[ind][-1]\n",
    "\n",
    "        return x,y\n",
    "\n",
    "class TestDataset(DatasetMLP):\n",
    "    def __getitem__(self,ind):\n",
    "        x=self.data[ind]\n",
    "        return x\n",
    "\n",
    "train_set_mlp=DatasetMLP(np.array(train_feature_vectors))\n",
    "val_set_mlp=DatasetMLP(np.array(val_feature_vectors))\n",
    "\n",
    "batch_size=20\n",
    "\n",
    "train_dataloder_mlp=DataLoader(train_set_mlp,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True)  \n",
    "\n",
    "val_dataloder_mlp=DataLoader(val_set_mlp,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f903230b-95f2-4447-965e-cb79293f2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#class MLP(nn.Module):\n",
    "#    def __init__(self, input_dim):\n",
    "#        super(MLP, self).__init__()\n",
    "        #self.linear = nn.Linear(input_dim, 2)  # Output 2 classes\n",
    "    \n",
    "#    def forward(self, x):\n",
    "#        out = self.linear(x)\n",
    "#        return out\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1=128, hidden_dim2=64, hidden_dim3=32, output_dim=1):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
    "        self.fc4 = nn.Linear(hidden_dim3, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        out = self.fc4(x)\n",
    "        return out\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_data in dataloader:\n",
    "            x, y = input_data\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device).long()\n",
    "\n",
    "            output = model(x)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "            batch_predictions = predicted.cpu().detach().numpy().tolist()\n",
    "            batch_true_labels = y.cpu().detach().numpy().tolist()\n",
    "\n",
    "            predictions.extend(batch_predictions)\n",
    "            true_labels.extend(batch_true_labels)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(output, y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    # Compute average validation loss\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "\n",
    "    # Compute balanced accuracy\n",
    "    predictions = np.array(predictions)\n",
    "    true_labels = np.array(true_labels)\n",
    "    balanced_accuracy = balanced_accuracy_score(true_labels, predictions)\n",
    "\n",
    "    return balanced_accuracy, avg_loss, predictions, true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbd740b5-936f-4b6f-b460-a46617d914f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=523264, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([20])) must be the same as input size (torch.Size([20, 1]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mlong()  \u001b[38;5;66;03m# Ensure y is of type long for CrossEntropyLoss\u001b[39;00m\n\u001b[1;32m     46\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 47\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[1;32m     48\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     49\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/nn/modules/loss.py:731\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target,\n\u001b[1;32m    732\u001b[0m                                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    733\u001b[0m                                               pos_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_weight,\n\u001b[1;32m    734\u001b[0m                                               reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction)\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/nn/functional.py:3207\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate Binary Cross Entropy between target and input logits.\u001b[39;00m\n\u001b[1;32m   3167\u001b[0m \n\u001b[1;32m   3168\u001b[0m \u001b[38;5;124;03mSee :class:`~torch.nn.BCEWithLogitsLoss` for details.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3204\u001b[0m \u001b[38;5;124;03m     >>> loss.backward()\u001b[39;00m\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight):\n\u001b[0;32m-> 3207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   3208\u001b[0m         binary_cross_entropy_with_logits,\n\u001b[1;32m   3209\u001b[0m         (\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight),\n\u001b[1;32m   3210\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3211\u001b[0m         target,\n\u001b[1;32m   3212\u001b[0m         weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[1;32m   3213\u001b[0m         size_average\u001b[38;5;241m=\u001b[39msize_average,\n\u001b[1;32m   3214\u001b[0m         reduce\u001b[38;5;241m=\u001b[39mreduce,\n\u001b[1;32m   3215\u001b[0m         reduction\u001b[38;5;241m=\u001b[39mreduction,\n\u001b[1;32m   3216\u001b[0m         pos_weight\u001b[38;5;241m=\u001b[39mpos_weight,\n\u001b[1;32m   3217\u001b[0m     )\n\u001b[1;32m   3218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3219\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_enum(size_average, reduce)\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/overrides.py:1619\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[0;32m-> 1619\u001b[0m         result \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39m__torch_function__(public_api, types, args, kwargs)\n\u001b[1;32m   1620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1621\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/nn/functional.py:3224\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3221\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m-> 3224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([20])) must be the same as input size (torch.Size([20, 1]))"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "\n",
    "seed = 42\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "input_dim = 523264\n",
    "model = MLP(input_dim).to(device)\n",
    "\n",
    "initial_lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion=nn.BCEWithLogitsLoss()\n",
    "# Assuming optimizer is already defined\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "print(model)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "model.train()\n",
    "train_avg_loss_list=[]\n",
    "val_avg_loss_list=[]\n",
    "train_balanced_accuracy_list=[]\n",
    "val_balanced_accuracy_list=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for batch_num, input_data in enumerate(train_dataloder_mlp):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = input_data\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).long()  # Ensure y is of type long for CrossEntropyLoss\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Convert predictions to class labels (0 or 1)\n",
    "\n",
    "        \n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        batch_predictions = predicted.cpu().detach().numpy().tolist()\n",
    "        batch_true_labels = y.cpu().detach().numpy().tolist()\n",
    "\n",
    "        predictions.extend(batch_predictions)\n",
    "        true_labels.extend(batch_true_labels)\n",
    "\n",
    "        #if batch_num % 40 == 0:\n",
    "        #    print('\\tEpoch %d | Batch %d | Loss %6.2f' % (epoch, batch_num, loss.item()))\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    train_balanced_accuracy = balanced_accuracy_score(true_labels, predictions)\n",
    "    train_avg_loss=sum(losses)/len(losses) \n",
    "    print('Epoch %d | Train Loss %6.2f| Train Balanced Accuracy %6.2f' % (epoch, train_avg_loss ,train_balanced_accuracy))\n",
    "    \n",
    "    val_balanced_accuracy, val_avg_loss, val_predictions, val_true_labels = evaluate(model, val_dataloder_mlp,criterion)\n",
    "    print('Epoch %d | Validation Loss %6.2f| Validation Balanced Accuracy: %6.2f' % (epoch, val_avg_loss, val_balanced_accuracy))\n",
    "\n",
    "    train_avg_loss_list.append(train_avg_loss)\n",
    "    val_avg_loss_list.append(val_avg_loss)\n",
    "    \n",
    "    train_balanced_accuracy_list.append(train_balanced_accuracy)\n",
    "    val_balanced_accuracy_list.append(val_balanced_accuracy)\n",
    "\n",
    "\n",
    "# Convert predictions and true labels to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Example of using predictions and true labels\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"True Labels:\", true_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "712671ff-5c00-4517-a0fb-10d188343430",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_true=true_labels,y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2064c851-e345-4857-a66b-19c78c92893c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_feature_vectors=utils.get_feature_vectors(dataloader=test_dataloader,\n",
    "                                                dataframe=test_data,\n",
    "                                                set_type='test', \n",
    "                                                feature_tensors=True)\n",
    "\n",
    "test_set_mlp=DatasetMLP(np.array(test_feature_vectors))\n",
    "\n",
    "test_dataloder_mlp=DataLoader(test_set_mlp,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee67db7-27a0-4d17-a3fc-b395f31bdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_balanced_accuracy, loss, test_predictions, test_true_labels = evaluate(model, test_dataloder_mlp, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9940711-b273-4b5b-aa45-e3bb106c33fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.82188746123172"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_balanced_accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae2c0c37-f039-4b7a-8737-801a765205fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df=pd.DataFrame(data={'train_avg_loss':train_avg_loss_list,\n",
    "                            'train_balanced_accuracy':train_balanced_accuracy_list,\n",
    "                            'val_avg_loss':val_avg_loss_list,\n",
    "                            'val_balanced_accuracy':val_balanced_accuracy_list})\n",
    "metrics_df.to_csv('metrics_df_e11.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75822dbf-7bfa-4278-868f-ed294eaa162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_balanced_accuracy': train_balanced_accuracy\n",
    "        }, 'best_model_e11.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e6b00a-682d-4f66-bf37-2309087befc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_e11.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1024\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[1;32m   1026\u001b[0m                      map_location,\n\u001b[1;32m   1027\u001b[0m                      pickle_module,\n\u001b[1;32m   1028\u001b[0m                      overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[1;32m   1029\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1031\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/serialization.py:1446\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1444\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1445\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1446\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   1448\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1449\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1451\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/serialization.py:1416\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1415\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1416\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/serialization.py:1390\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1385\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1389\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1390\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1391\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1392\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1395\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/serialization.py:390\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 390\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(storage, location)\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(obj\u001b[38;5;241m.\u001b[39mnbytes(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(location))\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcuda(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/torch/_utils.py:114\u001b[0m, in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_type(indices, values, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mUntypedStorage(\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(), device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     untyped_storage\u001b[38;5;241m.\u001b[39mcopy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('best_model_e11.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "best_balanced_accuracy = checkpoint['best_balanced_accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "984bbeb7-72fc-4020-9fbe-415c7c93f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_test_e11=pd.DataFrame(data={'labels':true_labels,'predictions':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fec33a7-4709-42fa-b7ac-819eced12b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_test_e11.to_csv('predictions_df_test_e11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e86633c-b05d-4006-ac94-d05c9db87da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_val_e11=pd.DataFrame(data={'labels':val_true_labels,'predictions':val_predictions})\n",
    "predictions_df_val_e11.to_csv('predictions_df_val_e11.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symbolic_music",
   "language": "python",
   "name": "symbolic_music"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
