{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da995ba8-14b1-40d6-ba26-5175e2ce5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from miditok import REMI\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae38028f-fad3-451e-a3da-bafc259fe8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import features_vectors as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1a1751-25a7-4222-bc29-eb73c19a6ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'features_vectors' from '/mnt/nfs_share_magnet1/lafuente/symbolic_music/author-profiling/experiments/e16/features_vectors.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae5e4130-7212-4cb3-ad7f-a30ccb51fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "train_data=pd.read_csv(f'../../train data/k-folds_giant-midi_type0/giant-midi_type0_train_set_k{k}.csv')\n",
    "validation_data=pd.read_csv(f'../../train data/k-folds_giant-midi_type0/giant-midi_type0_test_set_k{k}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f860c2-b3d5-40cb-813e-f6b0f6d4c621",
   "metadata": {},
   "source": [
    "## 1. Get features vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71328b20-ffd4-4674-9990-f07257893fc5",
   "metadata": {},
   "source": [
    "### 1.1 Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5551ec47-e625-475f-863f-f0f03e0976ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs_share_magnet1/lafuente/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/miditok/midi_tokenizer.py:3252: UserWarning: The special token PAD_None is present twice in your configuration. Skipping its duplicated occurrence.\n",
      "  self.config = TokenizerConfig()\n",
      "/mnt/nfs_share_magnet1/lafuente/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/miditok/classes.py:702: UserWarning: The special token PAD_None is present twice in your configuration. Skipping its duplicated occurrence.\n",
      "  return cls(**input_dict, **kwargs)\n",
      "/mnt/nfs_share_magnet1/lafuente/miniconda3/envs/symbolic_music/lib/python3.12/site-packages/miditok/classes.py:702: UserWarning: Argument nb_tempos has been renamed num_tempos, you should consider to updateyour code with this new argument name.\n",
      "  return cls(**input_dict, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "val_dataloader=utils.create_data_loader(scores_df=validation_data,paths_column_name='type0_path')\n",
    "train_dataloader=utils.create_data_loader(scores_df=train_data,paths_column_name='type0_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6558569-e2d8-4c16-9702-854227399bd5",
   "metadata": {},
   "source": [
    "### 1.2 Get feature vectors from pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b266e69-1c68-4851-a33c-3652656db10f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "computing feature tensors:   0%|                | 1/311 [00:04<21:57,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   1%|                | 2/311 [00:07<18:39,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   1%|▏               | 3/311 [00:10<17:19,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   1%|▏               | 4/311 [00:13<16:55,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   2%|▎               | 5/311 [00:16<16:03,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   2%|▎               | 6/311 [00:19<15:33,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   2%|▎               | 7/311 [00:22<15:13,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   3%|▍               | 8/311 [00:25<15:09,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   3%|▍               | 9/311 [00:28<14:47,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   3%|▍              | 10/311 [00:31<14:42,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   4%|▌              | 11/311 [00:33<14:23,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   4%|▌              | 12/311 [00:36<14:26,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   4%|▋              | 13/311 [00:39<14:15,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   5%|▋              | 14/311 [00:42<14:15,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   5%|▋              | 15/311 [00:45<14:07,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   5%|▊              | 16/311 [00:48<14:02,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   5%|▊              | 17/311 [00:50<13:54,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   6%|▊              | 18/311 [00:53<13:46,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   6%|▉              | 19/311 [00:56<13:47,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   6%|▉              | 20/311 [00:59<13:41,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   7%|█              | 21/311 [01:02<13:38,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   7%|█              | 22/311 [01:05<13:37,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   7%|█              | 23/311 [01:07<13:27,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   8%|█▏             | 24/311 [01:10<13:23,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   8%|█▏             | 25/311 [01:13<13:23,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   8%|█▎             | 26/311 [01:16<13:18,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   9%|█▎             | 27/311 [01:18<13:13,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   9%|█▎             | 28/311 [01:21<13:10,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:   9%|█▍             | 29/311 [01:24<13:12,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  10%|█▍             | 30/311 [01:27<13:09,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  10%|█▍             | 31/311 [01:30<13:02,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  10%|█▌             | 32/311 [01:33<13:01,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  11%|█▌             | 33/311 [01:35<12:52,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  11%|█▋             | 34/311 [01:38<12:47,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  11%|█▋             | 35/311 [01:41<12:45,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  12%|█▋             | 36/311 [01:44<12:44,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  12%|█▊             | 37/311 [01:46<12:39,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  12%|█▊             | 38/311 [01:49<12:36,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  13%|█▉             | 39/311 [01:52<12:33,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  13%|█▉             | 40/311 [01:55<12:32,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  13%|█▉             | 41/311 [01:57<12:28,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  14%|██             | 42/311 [02:00<12:27,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  14%|██             | 43/311 [02:03<12:25,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  14%|██             | 44/311 [02:06<12:21,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  14%|██▏            | 45/311 [02:09<12:22,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  15%|██▏            | 46/311 [02:11<12:29,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  15%|██▎            | 47/311 [02:14<12:21,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  15%|██▎            | 48/311 [02:17<12:18,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  16%|██▎            | 49/311 [02:20<12:10,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  16%|██▍            | 50/311 [02:23<12:07,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  16%|██▍            | 51/311 [02:25<11:59,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  17%|██▌            | 52/311 [02:28<12:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  17%|██▌            | 53/311 [02:31<11:53,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  17%|██▌            | 54/311 [02:34<11:56,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  18%|██▋            | 55/311 [02:36<11:47,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  18%|██▋            | 56/311 [02:39<11:44,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  18%|██▋            | 57/311 [02:42<11:39,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  19%|██▊            | 58/311 [02:45<11:36,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  19%|██▊            | 59/311 [02:47<11:33,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  19%|██▉            | 60/311 [02:50<11:32,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  20%|██▉            | 61/311 [02:53<11:31,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing feature tensors:  20%|██▉            | 62/311 [02:56<11:32,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1008, 512])\n"
     ]
    }
   ],
   "source": [
    "train_feature_vectors=utils.get_feature_vectors(dataloader=train_dataloader,\n",
    "                                                dataframe=train_data,\n",
    "                                                set_type='train', \n",
    "                                                feature_tensors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6414a-63a6-46de-b21c-f989177caea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_feature_vectors=utils.get_feature_vectors(dataloader=val_dataloader,\n",
    "                                                dataframe=validation_data,\n",
    "                                                set_type='val', \n",
    "                                                feature_tensors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e30e8d-1a52-4d12-8f57-6bf20b95c113",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d995b-41e7-4249-ad5c-6ee128b09c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_feature_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3183b6-2b68-4ecf-a5da-206059acb9f1",
   "metadata": {},
   "source": [
    "## 2. Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b17966-7fcc-4286-90e8-3c89edc28f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "seed = 42\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "class DatasetMLP(Dataset):\n",
    "\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self,ind):\n",
    "        x=self.data[ind][:-1]\n",
    "        y=self.data[ind][-1]\n",
    "\n",
    "        return x,y\n",
    "\n",
    "train_set_mlp=DatasetMLP(np.array(train_feature_vectors))\n",
    "val_set_mlp=DatasetMLP(np.array(val_feature_vectors))\n",
    "\n",
    "batch_size=20\n",
    "\n",
    "train_dataloder_mlp=DataLoader(train_set_mlp,\n",
    "                              batch_size=batch_size,\n",
    "                               shuffle=True)  \n",
    "\n",
    "val_dataloder_mlp=DataLoader(val_set_mlp,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903230b-95f2-4447-965e-cb79293f2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#class MLP(nn.Module):\n",
    "#    def __init__(self, input_dim):\n",
    "#        super(MLP, self).__init__()\n",
    "#        self.linear = nn.Linear(input_dim, 2)  # Output 2 classes\n",
    "    \n",
    "#    def forward(self, x):\n",
    "#        out = self.linear(x)\n",
    "#        return out\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1=128, hidden_dim2=64, hidden_dim3=32, output_dim=2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
    "        self.fc4 = nn.Linear(hidden_dim3, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        out = self.fc4(x)\n",
    "        return out\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_data in dataloader:\n",
    "            x, y = input_data\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device).long()\n",
    "\n",
    "            output = model(x)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "            batch_predictions = predicted.cpu().detach().numpy().tolist()\n",
    "            batch_true_labels = y.cpu().detach().numpy().tolist()\n",
    "\n",
    "            predictions.extend(batch_predictions)\n",
    "            true_labels.extend(batch_true_labels)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(output, y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    # Compute average validation loss\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "\n",
    "    # Compute balanced accuracy\n",
    "    predictions = np.array(predictions)\n",
    "    true_labels = np.array(true_labels)\n",
    "    balanced_accuracy = balanced_accuracy_score(true_labels, predictions)\n",
    "\n",
    "    return balanced_accuracy, avg_loss, predictions, true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd740b5-936f-4b6f-b460-a46617d914f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "seed = 42\n",
    "if seed is not None:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "input_dim = 516096\n",
    "model = MLP(input_dim).to(device)\n",
    "\n",
    "#initial_lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Assuming optimizer is already defined\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "print(model)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "model.train()\n",
    "train_avg_loss_list=[]\n",
    "val_avg_loss_list=[]\n",
    "train_balanced_accuracy_list=[]\n",
    "val_balanced_accuracy_list=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for batch_num, input_data in enumerate(train_dataloder_mlp):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = input_data\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).long()  # Ensure y is of type long for CrossEntropyLoss\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # Convert predictions to class labels (0 or 1)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        batch_predictions = predicted.cpu().detach().numpy().tolist()\n",
    "        batch_true_labels = y.cpu().detach().numpy().tolist()\n",
    "\n",
    "        predictions.extend(batch_predictions)\n",
    "        true_labels.extend(batch_true_labels)\n",
    "\n",
    "        #if batch_num % 40 == 0:\n",
    "        #    print('\\tEpoch %d | Batch %d | Loss %6.2f' % (epoch, batch_num, loss.item()))\n",
    "    # Step the scheduler\n",
    "    #scheduler.step()\n",
    "    \n",
    "    train_balanced_accuracy = balanced_accuracy_score(true_labels, predictions)\n",
    "    train_avg_loss=sum(losses)/len(losses) \n",
    "    print('Epoch %d | Train Loss %6.2f| Train Balanced Accuracy %6.2f' % (epoch, train_avg_loss ,train_balanced_accuracy))\n",
    "    \n",
    "    val_balanced_accuracy, val_avg_loss, val_predictions, val_true_labels = evaluate(model, val_dataloder_mlp,criterion)\n",
    "    print('Epoch %d | Validation Loss %6.2f| Validation Balanced Accuracy: %6.2f' % (epoch, val_avg_loss, val_balanced_accuracy))\n",
    "\n",
    "    train_avg_loss_list.append(train_avg_loss)\n",
    "    val_avg_loss_list.append(val_avg_loss)\n",
    "    \n",
    "    train_balanced_accuracy_list.append(train_balanced_accuracy)\n",
    "    val_balanced_accuracy_list.append(val_balanced_accuracy)\n",
    "\n",
    "\n",
    "# Convert predictions and true labels to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Example of using predictions and true labels\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"True Labels:\", true_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712671ff-5c00-4517-a0fb-10d188343430",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_accuracy_score(y_true=true_labels,y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5003032-9845-41ec-bd78-8ac1d15f5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "predictions_df_train_e16=pd.DataFrame(data={'labels':true_labels,'predictions':predictions})\n",
    "predictions_df_train_e16.to_csv(f'predictions_df_train_e16_k{k}.csv')\n",
    "\n",
    "metrics_df=pd.DataFrame(data={'train_avg_loss':train_avg_loss_list,\n",
    "                            'train_balanced_accuracy':train_balanced_accuracy_list,\n",
    "                            'val_avg_loss':val_avg_loss_list,\n",
    "                            'val_balanced_accuracy':val_balanced_accuracy_list})\n",
    "\n",
    "metrics_df.to_csv(f'metrics_df_e16_k{k}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e86633c-b05d-4006-ac94-d05c9db87da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_val_e16=pd.DataFrame(data={'labels':val_true_labels,'predictions':val_predictions})\n",
    "predictions_df_val_e16.to_csv(f'predictions_df_test_e16_k{k}.csv')\n",
    "balanced_accuracy_score(y_true=val_true_labels,y_pred=val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3415a6-5bff-4fb9-bf77-1396124737c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hola')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symbolic_music",
   "language": "python",
   "name": "symbolic_music"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
